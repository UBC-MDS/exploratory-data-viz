---
params:
  dynamictitle: "module6_13"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module6/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import altair as alt
from altair_saver import save
import glob
from sklearn.pipeline import Pipeline, make_pipeline
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz

from IPython.display import HTML, display
from PIL import Image, ImageFile

from plot_classifier import plot_classifier
from sklearn.compose import make_column_transformer, ColumnTransformer

# Classifiers and regressors
from sklearn.dummy import DummyClassifier, DummyRegressor

# Preprocessing and pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics.pairwise import euclidean_distances

# train test split and cross validation
from sklearn.model_selection import cross_val_score, cross_validate, train_test_split
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier


pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

path = "../../../../static/module6/"
```


type: slides

# Make - pipelines & column transformers

Notes: <br>

---



```{python}
adult = pd.read_csv('data/adult.csv')
adult = adult.replace("?", np.NaN)
adult.head()
```

```{python}
train_df, test_df = train_test_split(adult, test_size=0.2, random_state=42)
```

Notes: 

Remember our Adult census data from assignment 5? Well, we are bringing back a more complete version of it. 

---

```{python}
X_train = train_df.drop(columns=['income'])
y_train = train_df['income']

X_test = test_df.drop(columns=['income'])
y_test = test_df['income']
```


Notes: 

Remember, we are trying to predict if a row is classified with an income <=50K or >50K.

---


```{python}
numeric_features = [
    "age",
    "fnlwgt",
    "education.num",
    "capital.gain",
    "capital.loss",
    "hours.per.week"
]

categorical_features = [
    "workclass",
    "education",
    "marital.status",
    "occupation",
    "relationship",
    "race",
    "sex",
    "native.country"
]

```

Notes: 

In the last slide deck, we split our features into numeric and categorical features which we will do again for this data.

---

```{python}
numeric_transformer = Pipeline(
    steps=[("imputer", SimpleImputer(strategy="median")), 
           ("scaler", StandardScaler())]
)

categorical_transformer = Pipeline(
    steps=[
        ("imputer", SimpleImputer(strategy="constant", fill_value="missing")),
        ("onehot", OneHotEncoder())]
)

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)]
)

pipe = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("clf", SVC())]
)
```


Notes: 

We defined transformations on the numeric and categorical features, on a column transformer, and on a pipeline.

This seems great but it seems quite a lot. 

Well, luckily there is another method and tool that is helpful in making our life easier. 

It's call `make_pipeline()`. 

---

### *make_pipeline* syntax


```{python}
from sklearn.pipeline import make_pipeline
```


```{python}
numeric_transformer = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())

categorical_transformer = make_pipeline(
    SimpleImputer(strategy="constant", fill_value="missing"),
    OneHotEncoder()
)

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

pipe = make_pipeline(preprocessor, SVC())
```


Notes: 

Let's create a column transformer and a pipeline using an alternative syntax `make_pipeline`. 

This is a shorthand for the `Pipeline` constructor and does not permit, naming the steps.

Instead, their names will be set to the lowercase of their types automatically.

---


## *make_column_transformer* syntax


```{python}
from sklearn.compose import make_column_transformer
```

so instead of this:

```{python}
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features) ],
         remainder='passthrough' 
)
```

we can do this:

```{python}
preprocessor = make_column_transformer(
    (numeric_transformer, numeric_features),
    (categorical_transformer, categorical_features),
     remainder='passthrough' )
```

Notes: 

Just like `make_pipeline()`,  we can make our column transformer with `make_column_transformer()`.

This eliminates the need to designate names for the numeric and categorical transformations. 


---

So our whole thing becomes:

```{python}
numeric_transformer = make_pipeline(SimpleImputer(strategy="median"),
                                    StandardScaler())


categorical_transformer = make_pipeline(
                SimpleImputer(strategy="constant", fill_value="missing"),
                OneHotEncoder(),
)
preprocessor = make_column_transformer(
               (numeric_transformer, numeric_features), 
               (categorical_transformer, categorical_features)
)
pipe = make_pipeline(preprocessor, SVC())
```


```python
scores = cross_validate(pipe, X_train, y_train, cv=5, return_train_score=True)
```

```out
ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform

Detailed traceback: 
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/usr/local/lib/python3.8/site-packages/joblib/parallel.py", line 1032, in __call__
    while self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.8/site-packages/joblib/parallel.py", line 847, in dispatch_one_batch
```


Notes: 

What's going on here??

---


```out
ValueError: Found unknown categories ['Holand-Netherlands'] in column 7 during transform

Detailed traceback: 
  File "<string>", line 1, in <module>
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py", line 72, in inner_f
    return f(**kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 242, in cross_validate
    scores = parallel(
  File "/usr/local/lib/python3.8/site-packages/joblib/parallel.py", line 1032, in __call__
    while self.dispatch_one_batch(iterator):
  File "/usr/local/lib/python3.8/site-packages/joblib/parallel.py", line 847, in dispatch_one_batch
```


```{python}
X_train["native.country"].value_counts().tail(5)
```



Notes: 

Let's look at the error message:

`Found unknown categories ['Holand-Netherlands'] in column 6 during transform`.

There is only one instance of Holand-Netherlands.

During cross-validation, this is getting put into the validation split.

By default, `OneHotEncoder` throws an error because you might want to know about this.

---

## How do we fix it? 


```{python}
numeric_transformer = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())

categorical_transformer = make_pipeline(
    SimpleImputer(strategy="constant", fill_value="missing"),
    OneHotEncoder(handle_unknown="ignore"),
)

preprocessor = make_column_transformer(
    (numeric_transformer, numeric_features), 
    (categorical_transformer, categorical_features)
)

pipe = make_pipeline(preprocessor, SVC())
```


```{python}
scores = cross_validate(pipe, X_train, y_train, cv=5, return_train_score=True)
pd.DataFrame(scores).mean()
```


Notes: 

Simplest fix: Pass `handle_unknown="ignore"` argument to `OneHotEncoder`.   

- It creates a row with all zeros. 

Do you want this behaviour though? 

In that case, "Holland" or "Mars" or "Hogwarts" would all be treated the same.

Are you expecting to get many unknown categories? Do you want to be able to distinguish between them?

With this approach, all unknown categories will be represented with all zeros. 



---

### Cases where it's OK to break the golden rule 

- If it's some fixed number of categories.


```{python}
all_countries = adult["native.country"].unique()
all_countries
```

```{python}
ohe_cat = OneHotEncoder(categories=all_countries)
```


Notes: 

Are there any cases where it's OK to break the golden rule?

- If it's some fixed number of categories.

For example, if the categories are provinces/territories of Canada, we know the possible values and we can just specify them.

If we know the categories, this might be a reasonable time to "violate the Golden Rule" (look at the test set) and just hard-code all the categories.

This syntax allows you to pre-define the categories.

---

# Letâ€™s apply what we learned!

Notes: <br>