---
params:
  dynamictitle: "module1_01"
title: "`r params$dynamictitle`"
output:
  md_document:
    variant: gfm
    pandoc_args: "--atx-headers"
---

```{r setup, include=FALSE}
library(rmarkdown)
library(reticulate)
library(knitr)
library(vegawidget)

# Make sure you are updating your title
knitr::opts_chunk$set(
    echo = TRUE,
    base.dir = ".",
    base.url = "/",
    fig.path = paste("../../../../static/module1/", params$dynamictitle,"/", sep = ""))

md_document_custom <- md_document(variant = "gfm")
output_format(
    knitr = NULL,
    pandoc = NULL,
    base_format = md_document_custom)
```

```{python, include=FALSE}
# Show all dataframe columns
import pandas as pd


pd.set_option('display.width', 350)
pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

# These Python functions are from SO
# and save the day since they allow statements to be executed AND return a value.
# The built-in `exec` does not return a value,
# and `eval` does not work with statements (assignment, imports, etc).
# Reticulate only provides a thin wrapper around `eval`,
# so it is not much use here.
# The actual reticulate code for processing Python code chunks
# is more complex than these functions.
import ast
import copy


def convertExpr2Expression(Expr):
        Expr.lineno = 0
        Expr.col_offset = 0
        result = ast.Expression(Expr.value, lineno=0, col_offset=0)
        return result

def exec_with_return(code):
    code_ast = ast.parse(code)

    init_ast = copy.deepcopy(code_ast)
    init_ast.body = code_ast.body[:-1]

    last_ast = copy.deepcopy(code_ast)
    last_ast.body = code_ast.body[-1:]

    exec(compile(init_ast, "<ast>", "exec"), globals())
    if type(last_ast.body[0]) == ast.Expr:
        return eval(compile(convertExpr2Expression(last_ast.body[0]), "<ast>", "eval"),globals())
    else:
        exec(compile(last_ast, "<ast>", "exec"),globals())
```

```{r include=FALSE}
# This hooks into the knitr machinery
# and appends a custom function to the standard RMarkdown source code evaluation.
# Here it is appending `to_json()` to Altair code,
# sending it to the Python function above for evaluation,
# and converting the result to SVG via vegawidget.
# The results cannot be assigned a variable for some reasons
# and the vector is needed for RMarkdown to output both the source code and the SVG result.
# The SVG introduces an unnecessary doctype string
# which can be removed by adding the following to `format_slides.R`:
# text <- gsub('&lt;!DOCTYPE svg PUBLIC .*&gt;', '', text)
default_source_hook <- knit_hooks$get('source')
knit_hooks$set(
    source = function(x, options) {
        # Using element-wise `&&` to avoid raising warning for multi-line R code chunks.
        # Python chunks are always one line.
        if (options$engine == "python" && grepl("alt.Chart(", x, fixed = T)) {
            c(default_source_hook(x, options), vw_to_svg(py$exec_with_return(paste(x, '.to_json()'))))}
        else {
            default_source_hook(x, options)}})

# To get the interactive vega HTML instead of SVG when knitting,
# the source hook needs to be changed from using `vw_to_svg` to using `knit_print.vegaspec`.
# The following line also need to be uncommented to register the knit_print S3 method properly for vegaspecs:
# vctrs::s3_register("knitr::knit_print", "vegaspec")
# In addition, there is a bug in RMarkdown or vegawidget
# which requires the function `as_vegaspec` to be run once separately for plots to show up.
# R is probably not loading the CDN or other HTML resources properly otherwise.
# Since so many workarounds are required for the above,
# I came up with this simpler way of rendering the HTML,
# which can replace the second element of the output vector (the svg part):
# gsub('<!DOCTYPE html>', '', py$exec_with_return(paste(x, '.to_html()')))
# It works when knitting in RStudio,
# but we still need Ines to fix the js script bug in her framework before using it here.

# The below is needed to remove "alt.Chart(...)" when knitting inside RStudio.
# However, when using the course framework, that line already removed for some reason.
# Not sure if this discrepancy comes from a bug in the framework, RMarkdown,
# or a if it is a setting somewhere.
# default_output_hook <- knit_hooks$get('output')
# knit_hooks$set(
#     output = function(x, options) {
#         if (options$engine == "python" && grepl("alt.Chart(", x, fixed = T)) {
#             # Swallow the output so that "alt.Chart(...)" is not printed
#         }
#         else {
#             default_output_hook(x, options)}})
```

type: slides

# How Can We Visualize Data?

Notes:
There is a plethora of visualization packages in Python.
This rich selection can be beneficial, but is also confusing,
especially when starting out trying to decide which one to choose.
A helpful distinction to make is between *low level* and *high level* plotting packages.

---

## Low level and high level visualization concepts

### Low level (imperative)

- Focus on plot construction details.
    - Often includes loops, low-level drawing commands, etc.
- Specify *how* something should be done
    - "Draw a red point for every observation that has value X in column A,
      a blue point for every observation that has value Y in column A, etc."

### High level (declarative)

- Focus on data and relationships.
    - Often includes data, graphical marks, and encoding channels.
- Specify *what* should be done
    - "Assign colors based on the values in column A"

Notes:
By *declarative*,
we mean that you can provide a high-level specification of *what* you want the visualization to include,
in terms of *data*, *graphical marks*, and *encoding channels*,
rather than having to specify *how* to implement the visualization in terms of for-loops, low-level drawing commands, *etc*.
For example,
you would say "color my data by the column 'country'"
instead of "go through this data frame and plot any observations of country1 in blue, any observations of country in red, etc".

Declarative visualization tools lets you think about **data and relationship**,
rather than **plot construction details**.
A key idea is that you declare links between data fields and visual encoding channels,
such as the x-axis, y-axis, color, *etc*.
The rest of the plot details are handled automatically.

---

## The Python plotting landscape

<img src="/module1/py-plotting-landscape.png" alt="The Python plotting landscape" width="100%"></img>

Notes:
In this image you can see the most commonly used Python plotting packages.
There are many more,
but these are the ones you are the most likely to hear about,
so it is good to know that they exist.
As you can see there are several high and low level language,
so how to we chose?
In this course we have chosen to use Altair,
because it is a powerful high level visualization tool 
with a clear and consistent syntax
that also allows us to add interactive components to our plots,
such as tooltips and selections.

---

## A high level grammar of graphics

- Simple grammatical components combine to create visualizations.
- The Altair visualization grammar consist of three main components:
    1. Create a chart.
    2. Add a graphical mark.
    3. Encode dataframe columns as visual channels.
- In code, it looks like this: `Chart(data).mark().encode(x, y, ...)`.

Notes:
The declarative plotting concept can be implemented in different ways.
Here we will describe how a visualization grammar
can be used similarly to how grammar in regular language
is used to build complex linguistic constructs.
A wide range of simple to sophisticated visualizations can be created using a concise grammar.
Thanks to this functional way of interfacing with data,
only minimal changes are required if the underlying data change or to change the type of plot.

One of the most prominent declarative statistical visualization libraries is [Altair](https://altair-viz.github.io/).
Altair offer a powerful and concise visualization grammar for quickly building a wide range of statistical graphics.
In brief, you first create a chart,
then you indicate which graphical marks should represent the data (points, lines, etc)
and finally you encode your dataframe colums as different visual channels (x, y, color, etc).

Enough talking,
let's code!

---
