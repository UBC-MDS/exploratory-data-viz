---
params:
  dynamictitle: "module1_17"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module1/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import glob
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LinearRegression, LogisticRegression
import matplotlib.pyplot as plt
from image_classifier import classify_image

from IPython.display import HTML, display
from PIL import Image, ImageFile
pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

```


type: slides

# Dummy Regression

Notes: 

Let‚Äôs build a baseline model for our regression problem.


---

### Building a baseline regression model

<br>
<br>
<br>
Baseline model:                   

**Averge target value**: always predicts the mean of the training set.



Notes: 

Let's build a ***baseline*** simple machine learning algorithm based on simple rules of thumb. 

For a regression problem, we are going to build a baseline model that always predicts the mean target value in the training set. 



---


## Data 

```{python}
classification_df = pd.read_csv("data/quiz2-grade-toy-regression.csv")
classification_df.head()
```



Notes: 

To demonstrate this we are going to bring in our toy regression dataset. 

As a reminder, the task here is to protect our `quiz2` score. 


---

## 1. Create  ùëã  and  ùë¶

ùëã  ‚Üí Feature vectors <br>
ùë¶  ‚Üí Target

```{python}
X = classification_df.drop(columns=["quiz2"])
y = classification_df["quiz2"]
```


Notes: 

Just like before, we separate our data into the feature table and the target, also known as ùëã and ùë¶. 


---

## 2. Create a regressor object

- `import` the appropriate regressor, in this case, `DummyRegressor`.
- Create an object of the regressor. 

```{python}
from sklearn.dummy import DummyRegressor

dummy_reg = DummyRegressor(strategy="mean")
```


Notes: 

Next, we create our regressor object.

This time instead of importing `DummyClassifier()`, we import `DummyRegessor` which will be used to create our baseline regression model. 

We specify in the `strategy` argument `mean`. With this strategy, the model will predict the mean target value in the training data. 

Here we are naming our model `dummy_reg`.




---

## 3. Fit the regressor

```{python results = 'hide'}
dummy_reg.fit(X, y)
```


Notes: 

The next step is fitting our regressor.

As usual, we call fit on our dummy regressor and we pass `X` and `y` into `fit()`. 

Our dummy regressor is a very simple model and all it is going to learn here is the mean prediction from the training data.



---

## 4. Predict the target of given examples

We can predict the mean of examples by calling `predict` on the classifier object. 

```{python}
single_obs = X.loc[[2]]
single_obs
```

```{python}
dummy_reg.predict(single_obs)
```




Notes: 

Now that we have trained our regressor, we can use it to predict targets for new examples.

First, let's try to predict the target value for a single observation. 

When we call `predict` on `dummy_reg` with this observation. We get a prediction of 86.285. 


---

```{python}
X
```



```{python}
dummy_reg.predict(X)
```





Notes:

We can predict on the full dataset `X` and when we do so, we get the value of 86.285 for every example. 
This makes sense because the prediction is the mean of the target column. 


---

## 5. Scoring your model

In the regression setting, `.score()` gives the R^2 of the model, i.e. the coefficient of determination of the prediction.




```{python}
print("The accuracy of the model on the training data:", (dummy_reg.score(X, y)).round(3))
```

Notes: 

Now let‚Äôs try to assess our model. 

In the case of regression, `score` gives something called an R^2 to assess our model. 

We will not be going into that much detail on it now but the best possible score for any model is 1.0 and for dummy classifiers, it is around 0. 

This can also be a negative (because the model can be arbitrarily worse)



---

# Let‚Äôs apply what we learned!

Notes: <br>